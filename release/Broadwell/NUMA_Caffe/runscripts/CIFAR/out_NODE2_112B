I0331 18:11:10.240614 132985 caffe.cpp:314] Using Virtual Devices 0, 1
I0331 18:11:10.241461 132985 solver.cpp:90] Initializing solver from parameters: 
test_iter: 0
test_interval: 2000
base_lr: 0.001
display: 800
max_iter: 800
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.004
snapshot: 10000
snapshot_prefix: "examples/cifar10/cifar10_full"
solver_mode: VIRTDEV
device_id: 0
net: "examples/cifar10/cifar10_full_train_test_bsize112.prototxt"
train_state {
  level: 0
  stage: ""
}
snapshot_after_train: false
snapshot_format: HDF5
I0331 18:11:10.241740 132985 solver.cpp:135] Creating training net from net file: examples/cifar10/cifar10_full_train_test_bsize112.prototxt
I0331 18:11:10.242471 132985 solver.cpp:140] param_.device_id() :0 scheduled at 0
I0331 18:11:10.245875 132985 cpu_info.cpp:452] Processor speed [MHz]: 2000
I0331 18:11:10.245888 132985 cpu_info.cpp:455] Total number of sockets: 4
I0331 18:11:10.245893 132985 cpu_info.cpp:458] Total number of CPU cores: 56
I0331 18:11:10.245896 132985 cpu_info.cpp:461] Total number of processors: 112
I0331 18:11:10.245899 132985 cpu_info.cpp:464] GPU is used: no
I0331 18:11:10.245903 132985 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I0331 18:11:10.245906 132985 cpu_info.cpp:470] OpenMP thread bind allowed: no
OMP: Info #204: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #202: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: {0,4,8,12,16,20,24,28,32,36,40,44,48,52}
OMP: Info #156: KMP_AFFINITY: 14 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 1 packages x 14 cores/pkg x 1 threads/core (14 total cores)
OMP: Info #206: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 
OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 1 
OMP: Info #171: KMP_AFFINITY: OS proc 8 maps to package 0 core 2 
OMP: Info #171: KMP_AFFINITY: OS proc 12 maps to package 0 core 3 
OMP: Info #171: KMP_AFFINITY: OS proc 16 maps to package 0 core 4 
OMP: Info #171: KMP_AFFINITY: OS proc 20 maps to package 0 core 5 
OMP: Info #171: KMP_AFFINITY: OS proc 24 maps to package 0 core 6 
OMP: Info #171: KMP_AFFINITY: OS proc 28 maps to package 0 core 8 
OMP: Info #171: KMP_AFFINITY: OS proc 32 maps to package 0 core 9 
OMP: Info #171: KMP_AFFINITY: OS proc 36 maps to package 0 core 10 
OMP: Info #171: KMP_AFFINITY: OS proc 40 maps to package 0 core 11 
OMP: Info #171: KMP_AFFINITY: OS proc 44 maps to package 0 core 12 
OMP: Info #171: KMP_AFFINITY: OS proc 48 maps to package 0 core 13 
OMP: Info #171: KMP_AFFINITY: OS proc 52 maps to package 0 core 14 
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 0 bound to OS proc set {0}
I0331 18:11:10.247210 132985 cpu_info.cpp:473] Number of OpenMP threads: 14
I0331 18:11:10.247300 132985 net.cpp:493] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0331 18:11:10.247318 132985 net.cpp:493] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0331 18:11:10.247834 132985 net.cpp:125] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb"
    batch_size: 112
    backend: LMDB
    shuffle: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 250
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0331 18:11:10.247889 132985 net.cpp:154] Setting up Layer of device :0 @cpu 0 Layer : cifar
I0331 18:11:10.247896 132985 layer_factory.hpp:114] Creating layer cifar
I0331 18:11:10.248900 132985 net.cpp:169] Creating Layer cifar
I0331 18:11:10.248917 132985 net.cpp:579] cifar -> data
I0331 18:11:10.248921 132985 net.cpp:582] From AppendTop @cpu: 0
I0331 18:11:10.248941 132985 net.cpp:579] cifar -> label
I0331 18:11:10.248945 132985 net.cpp:582] From AppendTop @cpu: 0
I0331 18:11:10.248960 132985 data_transformer.cpp:62] Loading mean file from: examples/cifar10/mean.binaryproto
I0331 18:11:10.249248 132986 db_lmdb.cpp:72] Opened lmdb examples/cifar10/cifar10_train_lmdb
I0331 18:11:10.252997 132986 data_reader.cpp:198] Shuffling data
I0331 18:11:10.254019 132986 virtDev_device.cpp:310] found a CPU core 14 for Data Reader on device 0 thread ID 140057825883904
I0331 18:11:10.254027 132986 data_reader.cpp:128] inside DATAREADER 2
I0331 18:11:10.254101 132985 data_layer.cpp:80] output data size: 112,3,32,32
I0331 18:11:10.256330 132985 base_data_layer.cpp:96] Done cpu data
I0331 18:11:10.256345 132985 net.cpp:219] Setting up cifar
I0331 18:11:10.256357 132985 net.cpp:226] Top shape: 112 3 32 32 (344064)
I0331 18:11:10.256363 132985 net.cpp:226] Top shape: 112 (112)
I0331 18:11:10.256367 132985 net.cpp:234] Memory required for data: 1376704
I0331 18:11:10.256376 132985 net.cpp:154] Setting up Layer of device :0 @cpu 4 Layer : conv1
I0331 18:11:10.256381 132985 layer_factory.hpp:114] Creating layer conv1
I0331 18:11:10.256397 132985 net.cpp:169] Creating Layer conv1
I0331 18:11:10.256402 132985 net.cpp:606] conv1 <- data
I0331 18:11:10.256410 132985 net.cpp:579] conv1 -> conv1
I0331 18:11:10.256414 132985 net.cpp:582] From AppendTop @cpu: 4
I0331 18:11:10.257926 132985 net.cpp:219] Setting up conv1
I0331 18:11:10.257938 132985 net.cpp:226] Top shape: 112 32 32 32 (3670016)
I0331 18:11:10.257942 132985 net.cpp:234] Memory required for data: 16056768
I0331 18:11:10.257963 132985 net.cpp:154] Setting up Layer of device :0 @cpu 4 Layer : pool1
I0331 18:11:10.257968 132985 layer_factory.hpp:114] Creating layer pool1
I0331 18:11:10.258010 132985 net.cpp:169] Creating Layer pool1
I0331 18:11:10.258015 132985 net.cpp:606] pool1 <- conv1
I0331 18:11:10.258030 132985 net.cpp:579] pool1 -> pool1
I0331 18:11:10.258034 132985 net.cpp:582] From AppendTop @cpu: 4
I0331 18:11:10.258050 132985 net.cpp:219] Setting up pool1
I0331 18:11:10.258056 132985 net.cpp:226] Top shape: 112 32 16 16 (917504)
I0331 18:11:10.258060 132985 net.cpp:234] Memory required for data: 19726784
I0331 18:11:10.258065 132985 net.cpp:154] Setting up Layer of device :0 @cpu 4 Layer : relu1
I0331 18:11:10.258069 132985 layer_factory.hpp:114] Creating layer relu1
I0331 18:11:10.258077 132985 net.cpp:169] Creating Layer relu1
I0331 18:11:10.258081 132985 net.cpp:606] relu1 <- pool1
I0331 18:11:10.258087 132985 net.cpp:566] relu1 -> pool1 (in-place)
I0331 18:11:10.258095 132985 net.cpp:219] Setting up relu1
I0331 18:11:10.258100 132985 net.cpp:226] Top shape: 112 32 16 16 (917504)
I0331 18:11:10.258105 132985 net.cpp:234] Memory required for data: 23396800
I0331 18:11:10.258110 132985 net.cpp:154] Setting up Layer of device :0 @cpu 4 Layer : norm1
I0331 18:11:10.258112 132985 layer_factory.hpp:114] Creating layer norm1
I0331 18:11:10.258121 132985 net.cpp:169] Creating Layer norm1
I0331 18:11:10.258124 132985 net.cpp:606] norm1 <- pool1
I0331 18:11:10.258132 132985 net.cpp:579] norm1 -> norm1
I0331 18:11:10.258136 132985 net.cpp:582] From AppendTop @cpu: 4
I0331 18:11:10.258190 132985 net.cpp:219] Setting up norm1
I0331 18:11:10.258196 132985 net.cpp:226] Top shape: 112 32 16 16 (917504)
I0331 18:11:10.258200 132985 net.cpp:234] Memory required for data: 27066816
I0331 18:11:10.258216 132985 net.cpp:154] Setting up Layer of device :0 @cpu 4 Layer : conv2
I0331 18:11:10.258220 132985 layer_factory.hpp:114] Creating layer conv2
I0331 18:11:10.258234 132985 net.cpp:169] Creating Layer conv2
I0331 18:11:10.258239 132985 net.cpp:606] conv2 <- norm1
I0331 18:11:10.258245 132985 net.cpp:579] conv2 -> conv2
I0331 18:11:10.258249 132985 net.cpp:582] From AppendTop @cpu: 4
I0331 18:11:10.263823 132985 net.cpp:219] Setting up conv2
I0331 18:11:10.263835 132985 net.cpp:226] Top shape: 112 32 16 16 (917504)
I0331 18:11:10.263839 132985 net.cpp:234] Memory required for data: 30736832
I0331 18:11:10.263850 132985 net.cpp:154] Setting up Layer of device :0 @cpu 4 Layer : relu2
I0331 18:11:10.263855 132985 layer_factory.hpp:114] Creating layer relu2
I0331 18:11:10.263862 132985 net.cpp:169] Creating Layer relu2
I0331 18:11:10.263866 132985 net.cpp:606] relu2 <- conv2
I0331 18:11:10.263875 132985 net.cpp:566] relu2 -> conv2 (in-place)
I0331 18:11:10.263881 132985 net.cpp:219] Setting up relu2
I0331 18:11:10.263886 132985 net.cpp:226] Top shape: 112 32 16 16 (917504)
I0331 18:11:10.263890 132985 net.cpp:234] Memory required for data: 34406848
I0331 18:11:10.263895 132985 net.cpp:154] Setting up Layer of device :0 @cpu 4 Layer : pool2
I0331 18:11:10.263898 132985 layer_factory.hpp:114] Creating layer pool2
I0331 18:11:10.263918 132985 net.cpp:169] Creating Layer pool2
I0331 18:11:10.263922 132985 net.cpp:606] pool2 <- conv2
I0331 18:11:10.263932 132985 net.cpp:579] pool2 -> pool2
I0331 18:11:10.263936 132985 net.cpp:582] From AppendTop @cpu: 4
I0331 18:11:10.263943 132985 net.cpp:219] Setting up pool2
I0331 18:11:10.263949 132985 net.cpp:226] Top shape: 112 32 8 8 (229376)
I0331 18:11:10.263952 132985 net.cpp:234] Memory required for data: 35324352
I0331 18:11:10.263957 132985 net.cpp:154] Setting up Layer of device :0 @cpu 4 Layer : norm2
I0331 18:11:10.263962 132985 layer_factory.hpp:114] Creating layer norm2
I0331 18:11:10.263970 132985 net.cpp:169] Creating Layer norm2
I0331 18:11:10.263974 132985 net.cpp:606] norm2 <- pool2
I0331 18:11:10.263979 132985 net.cpp:579] norm2 -> norm2
I0331 18:11:10.263983 132985 net.cpp:582] From AppendTop @cpu: 4
I0331 18:11:10.264015 132985 net.cpp:219] Setting up norm2
I0331 18:11:10.264021 132985 net.cpp:226] Top shape: 112 32 8 8 (229376)
I0331 18:11:10.264024 132985 net.cpp:234] Memory required for data: 36241856
I0331 18:11:10.264029 132985 net.cpp:154] Setting up Layer of device :0 @cpu 4 Layer : conv3
I0331 18:11:10.264034 132985 layer_factory.hpp:114] Creating layer conv3
I0331 18:11:10.264050 132985 net.cpp:169] Creating Layer conv3
I0331 18:11:10.264053 132985 net.cpp:606] conv3 <- norm2
I0331 18:11:10.264061 132985 net.cpp:579] conv3 -> conv3
I0331 18:11:10.264065 132985 net.cpp:582] From AppendTop @cpu: 4
I0331 18:11:10.267719 132985 net.cpp:219] Setting up conv3
I0331 18:11:10.267731 132985 net.cpp:226] Top shape: 112 64 8 8 (458752)
I0331 18:11:10.267735 132985 net.cpp:234] Memory required for data: 38076864
I0331 18:11:10.267747 132985 net.cpp:154] Setting up Layer of device :0 @cpu 4 Layer : relu3
I0331 18:11:10.267751 132985 layer_factory.hpp:114] Creating layer relu3
I0331 18:11:10.267761 132985 net.cpp:169] Creating Layer relu3
I0331 18:11:10.267765 132985 net.cpp:606] relu3 <- conv3
I0331 18:11:10.267771 132985 net.cpp:566] relu3 -> conv3 (in-place)
I0331 18:11:10.267778 132985 net.cpp:219] Setting up relu3
I0331 18:11:10.267783 132985 net.cpp:226] Top shape: 112 64 8 8 (458752)
I0331 18:11:10.267787 132985 net.cpp:234] Memory required for data: 39911872
I0331 18:11:10.267791 132985 net.cpp:154] Setting up Layer of device :0 @cpu 4 Layer : pool3
I0331 18:11:10.267796 132985 layer_factory.hpp:114] Creating layer pool3
I0331 18:11:10.267817 132985 net.cpp:169] Creating Layer pool3
I0331 18:11:10.267822 132985 net.cpp:606] pool3 <- conv3
I0331 18:11:10.267827 132985 net.cpp:579] pool3 -> pool3
I0331 18:11:10.267832 132985 net.cpp:582] From AppendTop @cpu: 4
I0331 18:11:10.267838 132985 net.cpp:219] Setting up pool3
I0331 18:11:10.267843 132985 net.cpp:226] Top shape: 112 64 4 4 (114688)
I0331 18:11:10.267858 132985 net.cpp:234] Memory required for data: 40370624
I0331 18:11:10.267863 132985 net.cpp:154] Setting up Layer of device :0 @cpu 4 Layer : ip1
I0331 18:11:10.267866 132985 layer_factory.hpp:114] Creating layer ip1
I0331 18:11:10.267880 132985 net.cpp:169] Creating Layer ip1
I0331 18:11:10.267884 132985 net.cpp:606] ip1 <- pool3
I0331 18:11:10.267890 132985 net.cpp:579] ip1 -> ip1
I0331 18:11:10.267896 132985 net.cpp:582] From AppendTop @cpu: 4
I0331 18:11:10.268111 132985 net.cpp:219] Setting up ip1
I0331 18:11:10.268117 132985 net.cpp:226] Top shape: 112 10 (1120)
I0331 18:11:10.268121 132985 net.cpp:234] Memory required for data: 40375104
I0331 18:11:10.268129 132985 net.cpp:154] Setting up Layer of device :0 @cpu 4 Layer : loss
I0331 18:11:10.268133 132985 layer_factory.hpp:114] Creating layer loss
I0331 18:11:10.268141 132985 net.cpp:169] Creating Layer loss
I0331 18:11:10.268146 132985 net.cpp:606] loss <- ip1
I0331 18:11:10.268151 132985 net.cpp:606] loss <- label
I0331 18:11:10.268157 132985 net.cpp:579] loss -> loss
I0331 18:11:10.268160 132985 net.cpp:582] From AppendTop @cpu: 4
I0331 18:11:10.268174 132985 layer_factory.hpp:114] Creating layer loss
I0331 18:11:10.268203 132985 net.cpp:219] Setting up loss
I0331 18:11:10.268208 132985 net.cpp:226] Top shape: (1)
I0331 18:11:10.268213 132985 net.cpp:229]     with loss weight 1
I0331 18:11:10.268242 132985 net.cpp:234] Memory required for data: 40375108
I0331 18:11:10.268246 132985 net.cpp:296] loss needs backward computation.
I0331 18:11:10.268250 132985 net.cpp:296] ip1 needs backward computation.
I0331 18:11:10.268254 132985 net.cpp:296] pool3 needs backward computation.
I0331 18:11:10.268259 132985 net.cpp:296] relu3 needs backward computation.
I0331 18:11:10.268261 132985 net.cpp:296] conv3 needs backward computation.
I0331 18:11:10.268265 132985 net.cpp:296] norm2 needs backward computation.
I0331 18:11:10.268270 132985 net.cpp:296] pool2 needs backward computation.
I0331 18:11:10.268273 132985 net.cpp:296] relu2 needs backward computation.
I0331 18:11:10.268276 132985 net.cpp:296] conv2 needs backward computation.
I0331 18:11:10.268280 132985 net.cpp:296] norm1 needs backward computation.
I0331 18:11:10.268285 132985 net.cpp:296] relu1 needs backward computation.
I0331 18:11:10.268287 132985 net.cpp:296] pool1 needs backward computation.
I0331 18:11:10.268291 132985 net.cpp:296] conv1 needs backward computation.
I0331 18:11:10.268296 132985 net.cpp:298] cifar does not need backward computation.
I0331 18:11:10.268304 132985 net.cpp:340] This network produces output loss
I0331 18:11:10.268318 132985 net.cpp:354] Network initialization done.
I0331 18:11:10.269083 132985 solver.cpp:227] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_train_test_bsize112.prototxt
I0331 18:11:10.269098 132985 cpu_info.cpp:452] Processor speed [MHz]: 2000
I0331 18:11:10.269103 132985 cpu_info.cpp:455] Total number of sockets: 4
I0331 18:11:10.269106 132985 cpu_info.cpp:458] Total number of CPU cores: 56
I0331 18:11:10.269109 132985 cpu_info.cpp:461] Total number of processors: 112
I0331 18:11:10.269114 132985 cpu_info.cpp:464] GPU is used: no
I0331 18:11:10.269116 132985 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I0331 18:11:10.269119 132985 cpu_info.cpp:470] OpenMP thread bind allowed: no
I0331 18:11:10.269124 132985 cpu_info.cpp:473] Number of OpenMP threads: 14
I0331 18:11:10.269158 132985 net.cpp:493] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0331 18:11:10.269646 132985 net.cpp:125] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "label_cifar_1_split"
  type: "Split"
  bottom: "label"
  top: "label_cifar_1_split_0"
  top: "label_cifar_1_split_1"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 250
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip1_ip1_0_split"
  type: "Split"
  bottom: "ip1"
  top: "ip1_ip1_0_split_0"
  top: "ip1_ip1_0_split_1"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1_ip1_0_split_0"
  bottom: "label_cifar_1_split_0"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1_ip1_0_split_1"
  bottom: "label_cifar_1_split_1"
  top: "loss"
}
I0331 18:11:10.269681 132985 net.cpp:154] Setting up Layer of device :0 @cpu 4 Layer : cifar
I0331 18:11:10.269686 132985 layer_factory.hpp:114] Creating layer cifar
I0331 18:11:10.269837 132985 net.cpp:169] Creating Layer cifar
I0331 18:11:10.269845 132985 net.cpp:579] cifar -> data
I0331 18:11:10.269850 132985 net.cpp:582] From AppendTop @cpu: 4
I0331 18:11:10.269862 132985 net.cpp:579] cifar -> label
I0331 18:11:10.269865 132985 net.cpp:582] From AppendTop @cpu: 4
I0331 18:11:10.269875 132985 data_transformer.cpp:62] Loading mean file from: examples/cifar10/mean.binaryproto
I0331 18:11:10.269975 132987 db_lmdb.cpp:72] Opened lmdb examples/cifar10/cifar10_test_lmdb
I0331 18:11:10.270002 132987 virtDev_device.cpp:310] found a CPU core 12 for Data Reader on device 0 thread ID 140057452713728
I0331 18:11:10.270007 132987 data_reader.cpp:128] inside DATAREADER 1
I0331 18:11:10.270088 132985 data_layer.cpp:80] output data size: 100,3,32,32
I0331 18:11:10.273517 132985 base_data_layer.cpp:96] Done cpu data
I0331 18:11:10.273532 132985 net.cpp:219] Setting up cifar
I0331 18:11:10.273540 132985 net.cpp:226] Top shape: 100 3 32 32 (307200)
I0331 18:11:10.273545 132985 net.cpp:226] Top shape: 100 (100)
I0331 18:11:10.273550 132985 net.cpp:234] Memory required for data: 1229200
I0331 18:11:10.273558 132985 net.cpp:154] Setting up Layer of device :0 @cpu 12 Layer : label_cifar_1_split
I0331 18:11:10.273573 132985 layer_factory.hpp:114] Creating layer label_cifar_1_split
I0331 18:11:10.273584 132985 net.cpp:169] Creating Layer label_cifar_1_split
I0331 18:11:10.273588 132985 net.cpp:606] label_cifar_1_split <- label
I0331 18:11:10.273596 132985 net.cpp:579] label_cifar_1_split -> label_cifar_1_split_0
I0331 18:11:10.273599 132985 net.cpp:582] From AppendTop @cpu: 12
I0331 18:11:10.273608 132985 net.cpp:579] label_cifar_1_split -> label_cifar_1_split_1
I0331 18:11:10.273612 132985 net.cpp:582] From AppendTop @cpu: 12
I0331 18:11:10.273620 132985 net.cpp:219] Setting up label_cifar_1_split
I0331 18:11:10.273630 132985 net.cpp:226] Top shape: 100 (100)
I0331 18:11:10.273638 132985 net.cpp:226] Top shape: 100 (100)
I0331 18:11:10.273640 132985 net.cpp:234] Memory required for data: 1230000
I0331 18:11:10.273645 132985 net.cpp:154] Setting up Layer of device :0 @cpu 12 Layer : conv1
I0331 18:11:10.273649 132985 layer_factory.hpp:114] Creating layer conv1
I0331 18:11:10.273660 132985 net.cpp:169] Creating Layer conv1
I0331 18:11:10.273664 132985 net.cpp:606] conv1 <- data
I0331 18:11:10.273670 132985 net.cpp:579] conv1 -> conv1
I0331 18:11:10.273674 132985 net.cpp:582] From AppendTop @cpu: 12
I0331 18:11:10.275717 132985 net.cpp:219] Setting up conv1
I0331 18:11:10.275728 132985 net.cpp:226] Top shape: 100 32 32 32 (3276800)
I0331 18:11:10.275732 132985 net.cpp:234] Memory required for data: 14337200
I0331 18:11:10.275745 132985 net.cpp:154] Setting up Layer of device :0 @cpu 12 Layer : pool1
I0331 18:11:10.275749 132985 layer_factory.hpp:114] Creating layer pool1
I0331 18:11:10.275773 132985 net.cpp:169] Creating Layer pool1
I0331 18:11:10.275777 132985 net.cpp:606] pool1 <- conv1
I0331 18:11:10.275785 132985 net.cpp:579] pool1 -> pool1
I0331 18:11:10.275789 132985 net.cpp:582] From AppendTop @cpu: 12
I0331 18:11:10.275799 132985 net.cpp:219] Setting up pool1
I0331 18:11:10.275805 132985 net.cpp:226] Top shape: 100 32 16 16 (819200)
I0331 18:11:10.275809 132985 net.cpp:234] Memory required for data: 17614000
I0331 18:11:10.275813 132985 net.cpp:154] Setting up Layer of device :0 @cpu 12 Layer : relu1
I0331 18:11:10.275817 132985 layer_factory.hpp:114] Creating layer relu1
I0331 18:11:10.275823 132985 net.cpp:169] Creating Layer relu1
I0331 18:11:10.275827 132985 net.cpp:606] relu1 <- pool1
I0331 18:11:10.275835 132985 net.cpp:566] relu1 -> pool1 (in-place)
I0331 18:11:10.275840 132985 net.cpp:219] Setting up relu1
I0331 18:11:10.275851 132985 net.cpp:226] Top shape: 100 32 16 16 (819200)
I0331 18:11:10.275854 132985 net.cpp:234] Memory required for data: 20890800
I0331 18:11:10.275858 132985 net.cpp:154] Setting up Layer of device :0 @cpu 12 Layer : norm1
I0331 18:11:10.275862 132985 layer_factory.hpp:114] Creating layer norm1
I0331 18:11:10.275868 132985 net.cpp:169] Creating Layer norm1
I0331 18:11:10.275871 132985 net.cpp:606] norm1 <- pool1
I0331 18:11:10.275876 132985 net.cpp:579] norm1 -> norm1
I0331 18:11:10.275880 132985 net.cpp:582] From AppendTop @cpu: 12
I0331 18:11:10.275916 132985 net.cpp:219] Setting up norm1
I0331 18:11:10.275923 132985 net.cpp:226] Top shape: 100 32 16 16 (819200)
I0331 18:11:10.275926 132985 net.cpp:234] Memory required for data: 24167600
I0331 18:11:10.275931 132985 net.cpp:154] Setting up Layer of device :0 @cpu 12 Layer : conv2
I0331 18:11:10.275934 132985 layer_factory.hpp:114] Creating layer conv2
I0331 18:11:10.275943 132985 net.cpp:169] Creating Layer conv2
I0331 18:11:10.275946 132985 net.cpp:606] conv2 <- norm1
I0331 18:11:10.275954 132985 net.cpp:579] conv2 -> conv2
I0331 18:11:10.275959 132985 net.cpp:582] From AppendTop @cpu: 12
I0331 18:11:10.281632 132985 net.cpp:219] Setting up conv2
I0331 18:11:10.281644 132985 net.cpp:226] Top shape: 100 32 16 16 (819200)
I0331 18:11:10.281647 132985 net.cpp:234] Memory required for data: 27444400
I0331 18:11:10.281659 132985 net.cpp:154] Setting up Layer of device :0 @cpu 12 Layer : relu2
I0331 18:11:10.281663 132985 layer_factory.hpp:114] Creating layer relu2
I0331 18:11:10.281687 132985 net.cpp:169] Creating Layer relu2
I0331 18:11:10.281690 132985 net.cpp:606] relu2 <- conv2
I0331 18:11:10.281697 132985 net.cpp:566] relu2 -> conv2 (in-place)
I0331 18:11:10.281703 132985 net.cpp:219] Setting up relu2
I0331 18:11:10.281708 132985 net.cpp:226] Top shape: 100 32 16 16 (819200)
I0331 18:11:10.281711 132985 net.cpp:234] Memory required for data: 30721200
I0331 18:11:10.281716 132985 net.cpp:154] Setting up Layer of device :0 @cpu 12 Layer : pool2
I0331 18:11:10.281719 132985 layer_factory.hpp:114] Creating layer pool2
I0331 18:11:10.281739 132985 net.cpp:169] Creating Layer pool2
I0331 18:11:10.281744 132985 net.cpp:606] pool2 <- conv2
I0331 18:11:10.281751 132985 net.cpp:579] pool2 -> pool2
I0331 18:11:10.281754 132985 net.cpp:582] From AppendTop @cpu: 12
I0331 18:11:10.281762 132985 net.cpp:219] Setting up pool2
I0331 18:11:10.281769 132985 net.cpp:226] Top shape: 100 32 8 8 (204800)
I0331 18:11:10.281772 132985 net.cpp:234] Memory required for data: 31540400
I0331 18:11:10.281776 132985 net.cpp:154] Setting up Layer of device :0 @cpu 12 Layer : norm2
I0331 18:11:10.281780 132985 layer_factory.hpp:114] Creating layer norm2
I0331 18:11:10.281788 132985 net.cpp:169] Creating Layer norm2
I0331 18:11:10.281792 132985 net.cpp:606] norm2 <- pool2
I0331 18:11:10.281797 132985 net.cpp:579] norm2 -> norm2
I0331 18:11:10.281801 132985 net.cpp:582] From AppendTop @cpu: 12
I0331 18:11:10.281831 132985 net.cpp:219] Setting up norm2
I0331 18:11:10.281836 132985 net.cpp:226] Top shape: 100 32 8 8 (204800)
I0331 18:11:10.281841 132985 net.cpp:234] Memory required for data: 32359600
I0331 18:11:10.281844 132985 net.cpp:154] Setting up Layer of device :0 @cpu 12 Layer : conv3
I0331 18:11:10.281848 132985 layer_factory.hpp:114] Creating layer conv3
I0331 18:11:10.281858 132985 net.cpp:169] Creating Layer conv3
I0331 18:11:10.281862 132985 net.cpp:606] conv3 <- norm2
I0331 18:11:10.281867 132985 net.cpp:579] conv3 -> conv3
I0331 18:11:10.281872 132985 net.cpp:582] From AppendTop @cpu: 12
I0331 18:11:10.285600 132985 net.cpp:219] Setting up conv3
I0331 18:11:10.285611 132985 net.cpp:226] Top shape: 100 64 8 8 (409600)
I0331 18:11:10.285615 132985 net.cpp:234] Memory required for data: 33998000
I0331 18:11:10.285629 132985 net.cpp:154] Setting up Layer of device :0 @cpu 12 Layer : relu3
I0331 18:11:10.285634 132985 layer_factory.hpp:114] Creating layer relu3
I0331 18:11:10.285645 132985 net.cpp:169] Creating Layer relu3
I0331 18:11:10.285648 132985 net.cpp:606] relu3 <- conv3
I0331 18:11:10.285658 132985 net.cpp:566] relu3 -> conv3 (in-place)
I0331 18:11:10.285665 132985 net.cpp:219] Setting up relu3
I0331 18:11:10.285670 132985 net.cpp:226] Top shape: 100 64 8 8 (409600)
I0331 18:11:10.285675 132985 net.cpp:234] Memory required for data: 35636400
I0331 18:11:10.285678 132985 net.cpp:154] Setting up Layer of device :0 @cpu 12 Layer : pool3
I0331 18:11:10.285682 132985 layer_factory.hpp:114] Creating layer pool3
I0331 18:11:10.285701 132985 net.cpp:169] Creating Layer pool3
I0331 18:11:10.285704 132985 net.cpp:606] pool3 <- conv3
I0331 18:11:10.285713 132985 net.cpp:579] pool3 -> pool3
I0331 18:11:10.285717 132985 net.cpp:582] From AppendTop @cpu: 12
I0331 18:11:10.285724 132985 net.cpp:219] Setting up pool3
I0331 18:11:10.285729 132985 net.cpp:226] Top shape: 100 64 4 4 (102400)
I0331 18:11:10.285733 132985 net.cpp:234] Memory required for data: 36046000
I0331 18:11:10.285738 132985 net.cpp:154] Setting up Layer of device :0 @cpu 12 Layer : ip1
I0331 18:11:10.285742 132985 layer_factory.hpp:114] Creating layer ip1
I0331 18:11:10.285751 132985 net.cpp:169] Creating Layer ip1
I0331 18:11:10.285755 132985 net.cpp:606] ip1 <- pool3
I0331 18:11:10.285769 132985 net.cpp:579] ip1 -> ip1
I0331 18:11:10.285773 132985 net.cpp:582] From AppendTop @cpu: 12
I0331 18:11:10.285980 132985 net.cpp:219] Setting up ip1
I0331 18:11:10.285986 132985 net.cpp:226] Top shape: 100 10 (1000)
I0331 18:11:10.285990 132985 net.cpp:234] Memory required for data: 36050000
I0331 18:11:10.285998 132985 net.cpp:154] Setting up Layer of device :0 @cpu 12 Layer : ip1_ip1_0_split
I0331 18:11:10.286010 132985 layer_factory.hpp:114] Creating layer ip1_ip1_0_split
I0331 18:11:10.286017 132985 net.cpp:169] Creating Layer ip1_ip1_0_split
I0331 18:11:10.286021 132985 net.cpp:606] ip1_ip1_0_split <- ip1
I0331 18:11:10.286026 132985 net.cpp:579] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0331 18:11:10.286031 132985 net.cpp:582] From AppendTop @cpu: 12
I0331 18:11:10.286053 132985 net.cpp:579] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0331 18:11:10.286056 132985 net.cpp:582] From AppendTop @cpu: 12
I0331 18:11:10.286063 132985 net.cpp:219] Setting up ip1_ip1_0_split
I0331 18:11:10.286069 132985 net.cpp:226] Top shape: 100 10 (1000)
I0331 18:11:10.286073 132985 net.cpp:226] Top shape: 100 10 (1000)
I0331 18:11:10.286077 132985 net.cpp:234] Memory required for data: 36058000
I0331 18:11:10.286082 132985 net.cpp:154] Setting up Layer of device :0 @cpu 12 Layer : accuracy
I0331 18:11:10.286085 132985 layer_factory.hpp:114] Creating layer accuracy
I0331 18:11:10.286098 132985 net.cpp:169] Creating Layer accuracy
I0331 18:11:10.286103 132985 net.cpp:606] accuracy <- ip1_ip1_0_split_0
I0331 18:11:10.286108 132985 net.cpp:606] accuracy <- label_cifar_1_split_0
I0331 18:11:10.286113 132985 net.cpp:579] accuracy -> accuracy
I0331 18:11:10.286119 132985 net.cpp:582] From AppendTop @cpu: 12
I0331 18:11:10.286128 132985 net.cpp:219] Setting up accuracy
I0331 18:11:10.286134 132985 net.cpp:226] Top shape: (1)
I0331 18:11:10.286137 132985 net.cpp:234] Memory required for data: 36058004
I0331 18:11:10.286141 132985 net.cpp:154] Setting up Layer of device :0 @cpu 12 Layer : loss
I0331 18:11:10.286145 132985 layer_factory.hpp:114] Creating layer loss
I0331 18:11:10.286152 132985 net.cpp:169] Creating Layer loss
I0331 18:11:10.286156 132985 net.cpp:606] loss <- ip1_ip1_0_split_1
I0331 18:11:10.286161 132985 net.cpp:606] loss <- label_cifar_1_split_1
I0331 18:11:10.286166 132985 net.cpp:579] loss -> loss
I0331 18:11:10.286170 132985 net.cpp:582] From AppendTop @cpu: 12
I0331 18:11:10.286178 132985 layer_factory.hpp:114] Creating layer loss
I0331 18:11:10.286201 132985 net.cpp:219] Setting up loss
I0331 18:11:10.286206 132985 net.cpp:226] Top shape: (1)
I0331 18:11:10.286209 132985 net.cpp:229]     with loss weight 1
I0331 18:11:10.286217 132985 net.cpp:234] Memory required for data: 36058008
I0331 18:11:10.286221 132985 net.cpp:296] loss needs backward computation.
I0331 18:11:10.286226 132985 net.cpp:298] accuracy does not need backward computation.
I0331 18:11:10.286236 132985 net.cpp:296] ip1_ip1_0_split needs backward computation.
I0331 18:11:10.286239 132985 net.cpp:296] ip1 needs backward computation.
I0331 18:11:10.286243 132985 net.cpp:296] pool3 needs backward computation.
I0331 18:11:10.286247 132985 net.cpp:296] relu3 needs backward computation.
I0331 18:11:10.286250 132985 net.cpp:296] conv3 needs backward computation.
I0331 18:11:10.286254 132985 net.cpp:296] norm2 needs backward computation.
I0331 18:11:10.286257 132985 net.cpp:296] pool2 needs backward computation.
I0331 18:11:10.286262 132985 net.cpp:296] relu2 needs backward computation.
I0331 18:11:10.286265 132985 net.cpp:296] conv2 needs backward computation.
I0331 18:11:10.286269 132985 net.cpp:296] norm1 needs backward computation.
I0331 18:11:10.286273 132985 net.cpp:296] relu1 needs backward computation.
I0331 18:11:10.286276 132985 net.cpp:296] pool1 needs backward computation.
I0331 18:11:10.286279 132985 net.cpp:296] conv1 needs backward computation.
I0331 18:11:10.286284 132985 net.cpp:298] label_cifar_1_split does not need backward computation.
I0331 18:11:10.286289 132985 net.cpp:298] cifar does not need backward computation.
I0331 18:11:10.286293 132985 net.cpp:340] This network produces output accuracy
I0331 18:11:10.286296 132985 net.cpp:340] This network produces output loss
I0331 18:11:10.286314 132985 net.cpp:354] Network initialization done.
I0331 18:11:10.286393 132985 solver.cpp:104] Solver scaffolding done.
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 2 bound to OS proc set {8}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 1 bound to OS proc set {4}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 3 bound to OS proc set {12}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 4 bound to OS proc set {16}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 5 bound to OS proc set {20}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 6 bound to OS proc set {24}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 7 bound to OS proc set {28}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 8 bound to OS proc set {32}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 9 bound to OS proc set {36}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 10 bound to OS proc set {40}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 11 bound to OS proc set {44}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 12 bound to OS proc set {48}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 13 bound to OS proc set {52}
E0331 18:11:10.298770 132985 syncedmem.cpp:252] Free ptr from virtDev Set Ptr
E0331 18:11:10.299501 132985 syncedmem.cpp:252] Free ptr from virtDev Set Ptr
E0331 18:11:10.299518 132985 syncedmem.cpp:252] Free ptr from virtDev Set Ptr
I0331 18:11:10.299545 132985 parallel.cpp:709] Virtual pairs 0:1
I0331 18:11:10.300827 132985 solver.cpp:140] param_.device_id() :1 scheduled at 1
I0331 18:11:10.300860 132985 cpu_info.cpp:452] Processor speed [MHz]: 2000
I0331 18:11:10.300865 132985 cpu_info.cpp:455] Total number of sockets: 4
I0331 18:11:10.300869 132985 cpu_info.cpp:458] Total number of CPU cores: 56
I0331 18:11:10.300873 132985 cpu_info.cpp:461] Total number of processors: 112
I0331 18:11:10.300876 132985 cpu_info.cpp:464] GPU is used: no
I0331 18:11:10.300879 132985 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I0331 18:11:10.300884 132985 cpu_info.cpp:470] OpenMP thread bind allowed: no
I0331 18:11:10.300887 132985 cpu_info.cpp:473] Number of OpenMP threads: 14
I0331 18:11:10.301055 132985 net.cpp:154] Setting up Layer of device :1 @cpu 1 Layer : cifar
I0331 18:11:10.301203 132985 net.cpp:582] From AppendTop @cpu: 1
I0331 18:11:10.301219 132985 net.cpp:582] From AppendTop @cpu: 1
I0331 18:11:10.301473 132985 data_layer.cpp:80] output data size: 112,3,32,32
I0331 18:11:10.308394 132985 base_data_layer.cpp:96] Done cpu data
I0331 18:11:10.309741 132985 net.cpp:154] Setting up Layer of device :1 @cpu 1 Layer : conv1
I0331 18:11:10.309778 132985 net.cpp:582] From AppendTop @cpu: 1
I0331 18:11:10.311782 132985 net.cpp:154] Setting up Layer of device :1 @cpu 1 Layer : pool1
I0331 18:11:10.311835 132985 net.cpp:582] From AppendTop @cpu: 1
I0331 18:11:10.311852 132985 net.cpp:154] Setting up Layer of device :1 @cpu 1 Layer : relu1
I0331 18:11:10.311868 132985 net.cpp:154] Setting up Layer of device :1 @cpu 1 Layer : norm1
I0331 18:11:10.311883 132985 net.cpp:582] From AppendTop @cpu: 1
I0331 18:11:10.311935 132985 net.cpp:154] Setting up Layer of device :1 @cpu 1 Layer : conv2
I0331 18:11:10.311951 132985 net.cpp:582] From AppendTop @cpu: 1
I0331 18:11:10.317203 132985 net.cpp:154] Setting up Layer of device :1 @cpu 1 Layer : relu2
I0331 18:11:10.317229 132985 net.cpp:154] Setting up Layer of device :1 @cpu 1 Layer : pool2
I0331 18:11:10.317261 132985 net.cpp:582] From AppendTop @cpu: 1
I0331 18:11:10.317272 132985 net.cpp:154] Setting up Layer of device :1 @cpu 1 Layer : norm2
I0331 18:11:10.317286 132985 net.cpp:582] From AppendTop @cpu: 1
I0331 18:11:10.317327 132985 net.cpp:154] Setting up Layer of device :1 @cpu 1 Layer : conv3
I0331 18:11:10.317344 132985 net.cpp:582] From AppendTop @cpu: 1
I0331 18:11:10.321202 132985 net.cpp:154] Setting up Layer of device :1 @cpu 1 Layer : relu3
I0331 18:11:10.321224 132985 net.cpp:154] Setting up Layer of device :1 @cpu 1 Layer : pool3
I0331 18:11:10.321249 132985 net.cpp:582] From AppendTop @cpu: 1
I0331 18:11:10.321261 132985 net.cpp:154] Setting up Layer of device :1 @cpu 1 Layer : ip1
I0331 18:11:10.321279 132985 net.cpp:582] From AppendTop @cpu: 1
I0331 18:11:10.321499 132985 net.cpp:154] Setting up Layer of device :1 @cpu 1 Layer : loss
I0331 18:11:10.321516 132985 net.cpp:582] From AppendTop @cpu: 1
E0331 18:11:10.321640 132985 syncedmem.cpp:252] Free ptr from virtDev Set Ptr
E0331 18:11:10.321663 132985 syncedmem.cpp:252] Free ptr from virtDev Set Ptr
E0331 18:11:10.321671 132985 syncedmem.cpp:252] Free ptr from virtDev Set Ptr
E0331 18:11:10.321678 132985 syncedmem.cpp:252] Free ptr from virtDev Set Ptr
E0331 18:11:10.321686 132985 syncedmem.cpp:252] Free ptr from virtDev Set Ptr
E0331 18:11:10.321692 132985 syncedmem.cpp:252] Free ptr from virtDev Set Ptr
I0331 18:11:10.321760 132985 parallel.cpp:686] Starting Optimization
I0331 18:11:10.321799 132985 solver.cpp:353] Solving CIFAR10_full
I0331 18:11:10.321804 132985 solver.cpp:354] Learning Rate Policy: fixed
I0331 18:11:10.321929 132985 solver.cpp:419] Iteration 0, Testing net (#0)
I0331 18:11:10.321938 132985 net.cpp:881] Copying source layer cifar
I0331 18:11:10.321943 132985 net.cpp:881] Copying source layer conv1
I0331 18:11:10.321950 132985 net.cpp:881] Copying source layer pool1
I0331 18:11:10.321969 132985 net.cpp:881] Copying source layer relu1
I0331 18:11:10.321972 132985 net.cpp:881] Copying source layer norm1
I0331 18:11:10.321975 132985 net.cpp:881] Copying source layer conv2
I0331 18:11:10.321980 132985 net.cpp:881] Copying source layer relu2
I0331 18:11:10.321983 132985 net.cpp:881] Copying source layer pool2
I0331 18:11:10.321986 132985 net.cpp:881] Copying source layer norm2
I0331 18:11:10.321990 132985 net.cpp:881] Copying source layer conv3
I0331 18:11:10.321995 132985 net.cpp:881] Copying source layer relu3
I0331 18:11:10.321997 132985 net.cpp:881] Copying source layer pool3
I0331 18:11:10.322001 132985 net.cpp:881] Copying source layer ip1
I0331 18:11:10.322005 132985 net.cpp:881] Copying source layer loss
I0331 18:11:10.329926 133002 parallel.cpp:459]  solver_->param().device_id() 1 root_solver 1 thread ID 140056327640832
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 14 bound to OS proc set {0}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 18 bound to OS proc set {16}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 26 bound to OS proc set {48}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 20 bound to OS proc set {24}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 15 bound to OS proc set {4}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 27 bound to OS proc set {52}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 22 bound to OS proc set {32}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 24 bound to OS proc set {40}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 21 bound to OS proc set {28}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 16 bound to OS proc set {8}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 17 bound to OS proc set {12}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 23 bound to OS proc set {36}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 19 bound to OS proc set {20}
OMP: Info #242: KMP_AFFINITY: pid 132985 thread 25 bound to OS proc set {44}
I0331 18:11:10.485955 132985 solver.cpp:299] Iteration 0, loss = 2.30259
I0331 18:11:10.486044 132985 solver.cpp:316]     Train net output #0: loss = 2.30259 (* 1 = 2.30259 loss)
I0331 18:11:10.486057 132985 blocking_queue.cpp:87] on_gradients_ready waiting to copy gradients from children
I0331 18:11:10.512784 132985 sgd_solver.cpp:143] Iteration 0, lr = 0.001
I0331 18:11:42.367537 132985 blocking_queue.cpp:87] on_gradients_ready waiting to copy gradients from children
I0331 18:12:01.339771 132985 solver.cpp:395] Iteration 800, loss = 1.31497
I0331 18:12:01.339855 132985 solver.cpp:404] Optimization Done.
E0331 18:12:01.339925 132985 parallel.cpp:413] CAME HERE IN ~V2VSync
E0331 18:12:01.341835 132985 parallel.cpp:413] CAME HERE IN ~V2VSync
I0331 18:12:01.341861 132985 caffe.cpp:378] Optimization Done.

real	0m51.181s
user	13m45.913s
sys	0m38.035s
