I0331 13:08:10.106446 260737 caffe.cpp:259] Use CPU.
I0331 13:08:10.108302 260737 solver.cpp:90] Initializing solver from parameters: 
test_iter: 0
test_interval: 1000
base_lr: 0.01
display: 20
max_iter: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 10000
snapshot_prefix: "models/bvlc_alexnet/caffe_alexnet_train"
solver_mode: CPU
net: "models/bvlc_alexnet/train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
snapshot_after_train: false
I0331 13:08:10.114671 260737 solver.cpp:135] Creating training net from net file: models/bvlc_alexnet/train_val.prototxt
I0331 13:08:10.146992 260737 cpu_info.cpp:452] Processor speed [MHz]: 1300
I0331 13:08:10.147083 260737 cpu_info.cpp:455] Total number of sockets: 1
I0331 13:08:10.147114 260737 cpu_info.cpp:458] Total number of CPU cores: 64
I0331 13:08:10.147142 260737 cpu_info.cpp:461] Total number of processors: 256
I0331 13:08:10.147171 260737 cpu_info.cpp:464] GPU is used: no
I0331 13:08:10.147198 260737 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I0331 13:08:10.147227 260737 cpu_info.cpp:470] OpenMP thread bind allowed: no
OMP: Info #204: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #202: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223}
OMP: Info #156: KMP_AFFINITY: 128 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 1 packages x 32 cores/pkg x 4 threads/core (32 total cores)
OMP: Info #206: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 64 maps to package 0 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 128 maps to package 0 core 0 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 192 maps to package 0 core 0 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 65 maps to package 0 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 129 maps to package 0 core 1 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 193 maps to package 0 core 1 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 16 maps to package 0 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 80 maps to package 0 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 144 maps to package 0 core 2 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 208 maps to package 0 core 2 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 17 maps to package 0 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 81 maps to package 0 core 3 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 145 maps to package 0 core 3 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 209 maps to package 0 core 3 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 18 maps to package 0 core 10 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 82 maps to package 0 core 10 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 146 maps to package 0 core 10 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 210 maps to package 0 core 10 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 19 maps to package 0 core 11 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 83 maps to package 0 core 11 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 147 maps to package 0 core 11 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 211 maps to package 0 core 11 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 24 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 66 maps to package 0 core 24 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 130 maps to package 0 core 24 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 194 maps to package 0 core 24 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 25 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 67 maps to package 0 core 25 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 131 maps to package 0 core 25 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 195 maps to package 0 core 25 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 32 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 68 maps to package 0 core 32 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 132 maps to package 0 core 32 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 196 maps to package 0 core 32 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 33 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 69 maps to package 0 core 33 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 133 maps to package 0 core 33 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 197 maps to package 0 core 33 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 20 maps to package 0 core 34 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 84 maps to package 0 core 34 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 148 maps to package 0 core 34 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 212 maps to package 0 core 34 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 21 maps to package 0 core 35 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 85 maps to package 0 core 35 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 149 maps to package 0 core 35 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 213 maps to package 0 core 35 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 40 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 70 maps to package 0 core 40 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 134 maps to package 0 core 40 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 198 maps to package 0 core 40 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 41 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 71 maps to package 0 core 41 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 135 maps to package 0 core 41 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 199 maps to package 0 core 41 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 22 maps to package 0 core 42 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 86 maps to package 0 core 42 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 150 maps to package 0 core 42 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 214 maps to package 0 core 42 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 23 maps to package 0 core 43 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 87 maps to package 0 core 43 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 151 maps to package 0 core 43 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 215 maps to package 0 core 43 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 8 maps to package 0 core 48 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 72 maps to package 0 core 48 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 136 maps to package 0 core 48 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 200 maps to package 0 core 48 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 9 maps to package 0 core 49 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 73 maps to package 0 core 49 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 137 maps to package 0 core 49 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 201 maps to package 0 core 49 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 24 maps to package 0 core 50 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 88 maps to package 0 core 50 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 152 maps to package 0 core 50 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 216 maps to package 0 core 50 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 25 maps to package 0 core 51 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 89 maps to package 0 core 51 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 153 maps to package 0 core 51 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 217 maps to package 0 core 51 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 10 maps to package 0 core 56 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 74 maps to package 0 core 56 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 138 maps to package 0 core 56 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 202 maps to package 0 core 56 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 11 maps to package 0 core 57 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 75 maps to package 0 core 57 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 139 maps to package 0 core 57 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 203 maps to package 0 core 57 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 26 maps to package 0 core 58 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 90 maps to package 0 core 58 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 154 maps to package 0 core 58 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 218 maps to package 0 core 58 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 27 maps to package 0 core 59 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 91 maps to package 0 core 59 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 155 maps to package 0 core 59 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 219 maps to package 0 core 59 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 12 maps to package 0 core 64 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 76 maps to package 0 core 64 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 140 maps to package 0 core 64 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 204 maps to package 0 core 64 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 13 maps to package 0 core 65 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 77 maps to package 0 core 65 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 141 maps to package 0 core 65 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 205 maps to package 0 core 65 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 28 maps to package 0 core 66 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 92 maps to package 0 core 66 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 156 maps to package 0 core 66 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 220 maps to package 0 core 66 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 29 maps to package 0 core 67 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 93 maps to package 0 core 67 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 157 maps to package 0 core 67 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 221 maps to package 0 core 67 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 14 maps to package 0 core 72 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 78 maps to package 0 core 72 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 142 maps to package 0 core 72 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 206 maps to package 0 core 72 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 15 maps to package 0 core 73 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 79 maps to package 0 core 73 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 143 maps to package 0 core 73 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 207 maps to package 0 core 73 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 30 maps to package 0 core 74 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 94 maps to package 0 core 74 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 158 maps to package 0 core 74 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 222 maps to package 0 core 74 thread 3 
OMP: Info #171: KMP_AFFINITY: OS proc 31 maps to package 0 core 75 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 95 maps to package 0 core 75 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 159 maps to package 0 core 75 thread 2 
OMP: Info #171: KMP_AFFINITY: OS proc 223 maps to package 0 core 75 thread 3 
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 0 bound to OS proc set {0}
I0331 13:08:10.187664 260737 cpu_info.cpp:473] Number of OpenMP threads: 32
I0331 13:08:10.188043 260737 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0331 13:08:10.188134 260737 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0331 13:08:10.191601 260737 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/people/royp368/CN/caffe/caffe/data/ilsvrc12/imagenet_mean.binaryproto"
  }
  data_param {
    source: "/people/royp368/CN/caffe/caffe/examples/imagenet/ilsvrc12_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0331 13:08:10.191838 260737 layer_factory.hpp:114] Creating layer data
I0331 13:08:10.194367 260737 net.cpp:160] Creating Layer data
I0331 13:08:10.194458 260737 net.cpp:570] data -> data
I0331 13:08:10.194537 260737 net.cpp:570] data -> label
I0331 13:08:10.194602 260737 data_transformer.cpp:62] Loading mean file from: /people/royp368/CN/caffe/caffe/data/ilsvrc12/imagenet_mean.binaryproto
I0331 13:08:10.220572 260738 db_lmdb.cpp:72] Opened lmdb /people/royp368/CN/caffe/caffe/examples/imagenet/ilsvrc12_train_lmdb
I0331 13:08:10.436595 260737 data_layer.cpp:80] output data size: 256,3,227,227
I0331 13:08:10.757694 260737 net.cpp:210] Setting up data
I0331 13:08:10.757915 260737 net.cpp:217] Top shape: 256 3 227 227 (39574272)
I0331 13:08:10.757998 260737 net.cpp:217] Top shape: 256 (256)
I0331 13:08:10.758047 260737 net.cpp:225] Memory required for data: 158298112
I0331 13:08:10.758098 260737 layer_factory.hpp:114] Creating layer conv1
I0331 13:08:10.758195 260737 net.cpp:160] Creating Layer conv1
I0331 13:08:10.758249 260737 net.cpp:596] conv1 <- data
I0331 13:08:10.758308 260737 net.cpp:570] conv1 -> conv1
I0331 13:08:10.877233 260737 net.cpp:210] Setting up conv1
I0331 13:08:10.877363 260737 net.cpp:217] Top shape: 256 96 55 55 (74342400)
I0331 13:08:10.877411 260737 net.cpp:225] Memory required for data: 455667712
I0331 13:08:10.877523 260737 layer_factory.hpp:114] Creating layer relu1
I0331 13:08:10.877619 260737 net.cpp:160] Creating Layer relu1
I0331 13:08:10.877670 260737 net.cpp:596] relu1 <- conv1
I0331 13:08:10.877722 260737 net.cpp:557] relu1 -> conv1 (in-place)
I0331 13:08:10.877863 260737 net.cpp:210] Setting up relu1
I0331 13:08:10.877950 260737 net.cpp:217] Top shape: 256 96 55 55 (74342400)
I0331 13:08:10.878141 260737 net.cpp:225] Memory required for data: 753037312
I0331 13:08:10.878203 260737 layer_factory.hpp:114] Creating layer norm1
I0331 13:08:10.878280 260737 net.cpp:160] Creating Layer norm1
I0331 13:08:10.878322 260737 net.cpp:596] norm1 <- conv1
I0331 13:08:10.878377 260737 net.cpp:570] norm1 -> norm1
I0331 13:08:10.878464 260737 net.cpp:210] Setting up norm1
I0331 13:08:10.878517 260737 net.cpp:217] Top shape: 256 96 55 55 (74342400)
I0331 13:08:10.878552 260737 net.cpp:225] Memory required for data: 1050406912
I0331 13:08:10.878589 260737 layer_factory.hpp:114] Creating layer pool1
I0331 13:08:10.878834 260737 net.cpp:160] Creating Layer pool1
I0331 13:08:10.878919 260737 net.cpp:596] pool1 <- norm1
I0331 13:08:10.878980 260737 net.cpp:570] pool1 -> pool1
I0331 13:08:10.879077 260737 net.cpp:210] Setting up pool1
I0331 13:08:10.879139 260737 net.cpp:217] Top shape: 256 96 27 27 (17915904)
I0331 13:08:10.879173 260737 net.cpp:225] Memory required for data: 1122070528
I0331 13:08:10.879210 260737 layer_factory.hpp:114] Creating layer conv2
I0331 13:08:10.879274 260737 net.cpp:160] Creating Layer conv2
I0331 13:08:10.879312 260737 net.cpp:596] conv2 <- pool1
I0331 13:08:10.879362 260737 net.cpp:570] conv2 -> conv2
I0331 13:08:11.108496 260737 net.cpp:210] Setting up conv2
I0331 13:08:11.108628 260737 net.cpp:217] Top shape: 256 256 27 27 (47775744)
I0331 13:08:11.108711 260737 net.cpp:225] Memory required for data: 1313173504
I0331 13:08:11.108870 260737 layer_factory.hpp:114] Creating layer relu2
I0331 13:08:11.108979 260737 net.cpp:160] Creating Layer relu2
I0331 13:08:11.109046 260737 net.cpp:596] relu2 <- conv2
I0331 13:08:11.109115 260737 net.cpp:557] relu2 -> conv2 (in-place)
I0331 13:08:11.109195 260737 net.cpp:210] Setting up relu2
I0331 13:08:11.109256 260737 net.cpp:217] Top shape: 256 256 27 27 (47775744)
I0331 13:08:11.109292 260737 net.cpp:225] Memory required for data: 1504276480
I0331 13:08:11.109330 260737 layer_factory.hpp:114] Creating layer norm2
I0331 13:08:11.109385 260737 net.cpp:160] Creating Layer norm2
I0331 13:08:11.109424 260737 net.cpp:596] norm2 <- conv2
I0331 13:08:11.109474 260737 net.cpp:570] norm2 -> norm2
I0331 13:08:11.109549 260737 net.cpp:210] Setting up norm2
I0331 13:08:11.109599 260737 net.cpp:217] Top shape: 256 256 27 27 (47775744)
I0331 13:08:11.109632 260737 net.cpp:225] Memory required for data: 1695379456
I0331 13:08:11.109666 260737 layer_factory.hpp:114] Creating layer pool2
I0331 13:08:11.110031 260737 net.cpp:160] Creating Layer pool2
I0331 13:08:11.110129 260737 net.cpp:596] pool2 <- norm2
I0331 13:08:11.110204 260737 net.cpp:570] pool2 -> pool2
I0331 13:08:11.110296 260737 net.cpp:210] Setting up pool2
I0331 13:08:11.110363 260737 net.cpp:217] Top shape: 256 256 13 13 (11075584)
I0331 13:08:11.110404 260737 net.cpp:225] Memory required for data: 1739681792
I0331 13:08:11.110450 260737 layer_factory.hpp:114] Creating layer conv3
I0331 13:08:11.110527 260737 net.cpp:160] Creating Layer conv3
I0331 13:08:11.110576 260737 net.cpp:596] conv3 <- pool2
I0331 13:08:11.110641 260737 net.cpp:570] conv3 -> conv3
I0331 13:08:11.344656 260737 net.cpp:210] Setting up conv3
I0331 13:08:11.344831 260737 net.cpp:217] Top shape: 256 384 13 13 (16613376)
I0331 13:08:11.344900 260737 net.cpp:225] Memory required for data: 1806135296
I0331 13:08:11.344993 260737 layer_factory.hpp:114] Creating layer relu3
I0331 13:08:11.345067 260737 net.cpp:160] Creating Layer relu3
I0331 13:08:11.345118 260737 net.cpp:596] relu3 <- conv3
I0331 13:08:11.345172 260737 net.cpp:557] relu3 -> conv3 (in-place)
I0331 13:08:11.345235 260737 net.cpp:210] Setting up relu3
I0331 13:08:11.345284 260737 net.cpp:217] Top shape: 256 384 13 13 (16613376)
I0331 13:08:11.345319 260737 net.cpp:225] Memory required for data: 1872588800
I0331 13:08:11.345355 260737 layer_factory.hpp:114] Creating layer conv4
I0331 13:08:11.345423 260737 net.cpp:160] Creating Layer conv4
I0331 13:08:11.345464 260737 net.cpp:596] conv4 <- conv3
I0331 13:08:11.345520 260737 net.cpp:570] conv4 -> conv4
I0331 13:08:11.467427 260737 net.cpp:210] Setting up conv4
I0331 13:08:11.467552 260737 net.cpp:217] Top shape: 256 384 13 13 (16613376)
I0331 13:08:11.467598 260737 net.cpp:225] Memory required for data: 1939042304
I0331 13:08:11.467669 260737 layer_factory.hpp:114] Creating layer relu4
I0331 13:08:11.467736 260737 net.cpp:160] Creating Layer relu4
I0331 13:08:11.467835 260737 net.cpp:596] relu4 <- conv4
I0331 13:08:11.467896 260737 net.cpp:557] relu4 -> conv4 (in-place)
I0331 13:08:11.467958 260737 net.cpp:210] Setting up relu4
I0331 13:08:11.468006 260737 net.cpp:217] Top shape: 256 384 13 13 (16613376)
I0331 13:08:11.468039 260737 net.cpp:225] Memory required for data: 2005495808
I0331 13:08:11.468075 260737 layer_factory.hpp:114] Creating layer conv5
I0331 13:08:11.468138 260737 net.cpp:160] Creating Layer conv5
I0331 13:08:11.468176 260737 net.cpp:596] conv5 <- conv4
I0331 13:08:11.468228 260737 net.cpp:570] conv5 -> conv5
I0331 13:08:11.544821 260737 net.cpp:210] Setting up conv5
I0331 13:08:11.544947 260737 net.cpp:217] Top shape: 256 256 13 13 (11075584)
I0331 13:08:11.544999 260737 net.cpp:225] Memory required for data: 2049798144
I0331 13:08:11.545092 260737 layer_factory.hpp:114] Creating layer relu5
I0331 13:08:11.545168 260737 net.cpp:160] Creating Layer relu5
I0331 13:08:11.545217 260737 net.cpp:596] relu5 <- conv5
I0331 13:08:11.545301 260737 net.cpp:557] relu5 -> conv5 (in-place)
I0331 13:08:11.545373 260737 net.cpp:210] Setting up relu5
I0331 13:08:11.545423 260737 net.cpp:217] Top shape: 256 256 13 13 (11075584)
I0331 13:08:11.545457 260737 net.cpp:225] Memory required for data: 2094100480
I0331 13:08:11.545495 260737 layer_factory.hpp:114] Creating layer pool5
I0331 13:08:11.545613 260737 net.cpp:160] Creating Layer pool5
I0331 13:08:11.545662 260737 net.cpp:596] pool5 <- conv5
I0331 13:08:11.545717 260737 net.cpp:570] pool5 -> pool5
I0331 13:08:11.545837 260737 net.cpp:210] Setting up pool5
I0331 13:08:11.545907 260737 net.cpp:217] Top shape: 256 256 6 6 (2359296)
I0331 13:08:11.545940 260737 net.cpp:225] Memory required for data: 2103537664
I0331 13:08:11.545979 260737 layer_factory.hpp:114] Creating layer fc6
I0331 13:08:11.546046 260737 net.cpp:160] Creating Layer fc6
I0331 13:08:11.546084 260737 net.cpp:596] fc6 <- pool5
I0331 13:08:11.546133 260737 net.cpp:570] fc6 -> fc6
I0331 13:08:13.864416 260737 net.cpp:210] Setting up fc6
I0331 13:08:13.864540 260737 net.cpp:217] Top shape: 256 4096 (1048576)
I0331 13:08:13.864579 260737 net.cpp:225] Memory required for data: 2107731968
I0331 13:08:13.864639 260737 layer_factory.hpp:114] Creating layer relu6
I0331 13:08:13.864694 260737 net.cpp:160] Creating Layer relu6
I0331 13:08:13.864732 260737 net.cpp:596] relu6 <- fc6
I0331 13:08:13.864819 260737 net.cpp:557] relu6 -> fc6 (in-place)
I0331 13:08:13.864878 260737 net.cpp:210] Setting up relu6
I0331 13:08:13.864923 260737 net.cpp:217] Top shape: 256 4096 (1048576)
I0331 13:08:13.864953 260737 net.cpp:225] Memory required for data: 2111926272
I0331 13:08:13.864987 260737 layer_factory.hpp:114] Creating layer drop6
I0331 13:08:13.865052 260737 net.cpp:160] Creating Layer drop6
I0331 13:08:13.865088 260737 net.cpp:596] drop6 <- fc6
I0331 13:08:13.865131 260737 net.cpp:557] drop6 -> fc6 (in-place)
I0331 13:08:13.865195 260737 net.cpp:210] Setting up drop6
I0331 13:08:13.865236 260737 net.cpp:217] Top shape: 256 4096 (1048576)
I0331 13:08:13.865267 260737 net.cpp:225] Memory required for data: 2116120576
I0331 13:08:13.865299 260737 layer_factory.hpp:114] Creating layer fc7
I0331 13:08:13.865355 260737 net.cpp:160] Creating Layer fc7
I0331 13:08:13.865387 260737 net.cpp:596] fc7 <- fc6
I0331 13:08:13.865432 260737 net.cpp:570] fc7 -> fc7
I0331 13:08:14.895017 260737 net.cpp:210] Setting up fc7
I0331 13:08:14.895139 260737 net.cpp:217] Top shape: 256 4096 (1048576)
I0331 13:08:14.895179 260737 net.cpp:225] Memory required for data: 2120314880
I0331 13:08:14.895238 260737 layer_factory.hpp:114] Creating layer relu7
I0331 13:08:14.895294 260737 net.cpp:160] Creating Layer relu7
I0331 13:08:14.895458 260737 net.cpp:596] relu7 <- fc7
I0331 13:08:14.895519 260737 net.cpp:557] relu7 -> fc7 (in-place)
I0331 13:08:14.895579 260737 net.cpp:210] Setting up relu7
I0331 13:08:14.895624 260737 net.cpp:217] Top shape: 256 4096 (1048576)
I0331 13:08:14.895655 260737 net.cpp:225] Memory required for data: 2124509184
I0331 13:08:14.895689 260737 layer_factory.hpp:114] Creating layer drop7
I0331 13:08:14.895735 260737 net.cpp:160] Creating Layer drop7
I0331 13:08:14.895813 260737 net.cpp:596] drop7 <- fc7
I0331 13:08:14.895862 260737 net.cpp:557] drop7 -> fc7 (in-place)
I0331 13:08:14.895916 260737 net.cpp:210] Setting up drop7
I0331 13:08:14.895958 260737 net.cpp:217] Top shape: 256 4096 (1048576)
I0331 13:08:14.895988 260737 net.cpp:225] Memory required for data: 2128703488
I0331 13:08:14.896023 260737 layer_factory.hpp:114] Creating layer fc8
I0331 13:08:14.896078 260737 net.cpp:160] Creating Layer fc8
I0331 13:08:14.896112 260737 net.cpp:596] fc8 <- fc7
I0331 13:08:14.896157 260737 net.cpp:570] fc8 -> fc8
I0331 13:08:15.147910 260737 net.cpp:210] Setting up fc8
I0331 13:08:15.148027 260737 net.cpp:217] Top shape: 256 1000 (256000)
I0331 13:08:15.148061 260737 net.cpp:225] Memory required for data: 2129727488
I0331 13:08:15.148121 260737 layer_factory.hpp:114] Creating layer loss
I0331 13:08:15.148195 260737 net.cpp:160] Creating Layer loss
I0331 13:08:15.148260 260737 net.cpp:596] loss <- fc8
I0331 13:08:15.148303 260737 net.cpp:596] loss <- label
I0331 13:08:15.148349 260737 net.cpp:570] loss -> loss
I0331 13:08:15.148425 260737 layer_factory.hpp:114] Creating layer loss
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 1 bound to OS proc set {1}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 2 bound to OS proc set {16}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 3 bound to OS proc set {17}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 4 bound to OS proc set {18}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 5 bound to OS proc set {19}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 7 bound to OS proc set {3}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 6 bound to OS proc set {2}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 8 bound to OS proc set {4}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 9 bound to OS proc set {5}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 10 bound to OS proc set {20}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 11 bound to OS proc set {21}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 13 bound to OS proc set {7}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 12 bound to OS proc set {6}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 14 bound to OS proc set {22}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 15 bound to OS proc set {23}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 17 bound to OS proc set {9}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 16 bound to OS proc set {8}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 18 bound to OS proc set {24}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 19 bound to OS proc set {25}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 20 bound to OS proc set {10}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 21 bound to OS proc set {11}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 22 bound to OS proc set {26}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 23 bound to OS proc set {27}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 24 bound to OS proc set {12}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 25 bound to OS proc set {13}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 26 bound to OS proc set {28}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 27 bound to OS proc set {29}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 28 bound to OS proc set {14}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 29 bound to OS proc set {15}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 30 bound to OS proc set {30}
OMP: Info #242: KMP_AFFINITY: pid 260737 thread 31 bound to OS proc set {31}
I0331 13:08:15.171449 260737 net.cpp:210] Setting up loss
I0331 13:08:15.171552 260737 net.cpp:217] Top shape: (1)
I0331 13:08:15.171586 260737 net.cpp:220]     with loss weight 1
I0331 13:08:15.171690 260737 net.cpp:225] Memory required for data: 2129727492
I0331 13:08:15.171728 260737 net.cpp:287] loss needs backward computation.
I0331 13:08:15.171790 260737 net.cpp:287] fc8 needs backward computation.
I0331 13:08:15.171825 260737 net.cpp:287] drop7 needs backward computation.
I0331 13:08:15.171859 260737 net.cpp:287] relu7 needs backward computation.
I0331 13:08:15.171891 260737 net.cpp:287] fc7 needs backward computation.
I0331 13:08:15.171924 260737 net.cpp:287] drop6 needs backward computation.
I0331 13:08:15.171957 260737 net.cpp:287] relu6 needs backward computation.
I0331 13:08:15.171988 260737 net.cpp:287] fc6 needs backward computation.
I0331 13:08:15.172021 260737 net.cpp:287] pool5 needs backward computation.
I0331 13:08:15.172055 260737 net.cpp:287] relu5 needs backward computation.
I0331 13:08:15.172087 260737 net.cpp:287] conv5 needs backward computation.
I0331 13:08:15.172121 260737 net.cpp:287] relu4 needs backward computation.
I0331 13:08:15.172152 260737 net.cpp:287] conv4 needs backward computation.
I0331 13:08:15.172185 260737 net.cpp:287] relu3 needs backward computation.
I0331 13:08:15.172217 260737 net.cpp:287] conv3 needs backward computation.
I0331 13:08:15.172250 260737 net.cpp:287] pool2 needs backward computation.
I0331 13:08:15.172284 260737 net.cpp:287] norm2 needs backward computation.
I0331 13:08:15.172339 260737 net.cpp:287] relu2 needs backward computation.
I0331 13:08:15.172374 260737 net.cpp:287] conv2 needs backward computation.
I0331 13:08:15.172406 260737 net.cpp:287] pool1 needs backward computation.
I0331 13:08:15.172441 260737 net.cpp:287] norm1 needs backward computation.
I0331 13:08:15.172473 260737 net.cpp:287] relu1 needs backward computation.
I0331 13:08:15.172505 260737 net.cpp:287] conv1 needs backward computation.
I0331 13:08:15.172539 260737 net.cpp:289] data does not need backward computation.
I0331 13:08:15.172570 260737 net.cpp:331] This network produces output loss
I0331 13:08:15.172636 260737 net.cpp:345] Network initialization done.
I0331 13:08:15.179285 260737 solver.cpp:225] Creating test net (#0) specified by net file: models/bvlc_alexnet/train_val.prototxt
I0331 13:08:15.179375 260737 cpu_info.cpp:452] Processor speed [MHz]: 1300
I0331 13:08:15.179407 260737 cpu_info.cpp:455] Total number of sockets: 1
I0331 13:08:15.179541 260737 cpu_info.cpp:458] Total number of CPU cores: 64
I0331 13:08:15.179575 260737 cpu_info.cpp:461] Total number of processors: 256
I0331 13:08:15.179605 260737 cpu_info.cpp:464] GPU is used: no
I0331 13:08:15.179635 260737 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I0331 13:08:15.179663 260737 cpu_info.cpp:470] OpenMP thread bind allowed: no
I0331 13:08:15.179697 260737 cpu_info.cpp:473] Number of OpenMP threads: 32
I0331 13:08:15.179913 260737 net.cpp:484] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0331 13:08:15.183751 260737 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/people/royp368/CN/caffe/caffe/data/ilsvrc12/imagenet_mean.binaryproto"
  }
  data_param {
    source: "/people/royp368/CN/caffe/caffe/examples/imagenet/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "label_data_1_split"
  type: "Split"
  bottom: "label"
  top: "label_data_1_split_0"
  top: "label_data_1_split_1"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc8_fc8_0_split"
  type: "Split"
  bottom: "fc8"
  top: "fc8_fc8_0_split_0"
  top: "fc8_fc8_0_split_1"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_fc8_0_split_0"
  bottom: "label_data_1_split_0"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_fc8_0_split_1"
  bottom: "label_data_1_split_1"
  top: "loss"
}
I0331 13:08:15.183970 260737 layer_factory.hpp:114] Creating layer data
I0331 13:08:15.184357 260737 net.cpp:160] Creating Layer data
I0331 13:08:15.184422 260737 net.cpp:570] data -> data
I0331 13:08:15.184489 260737 net.cpp:570] data -> label
I0331 13:08:15.184546 260737 data_transformer.cpp:62] Loading mean file from: /people/royp368/CN/caffe/caffe/data/ilsvrc12/imagenet_mean.binaryproto
I0331 13:08:15.205162 260771 db_lmdb.cpp:72] Opened lmdb /people/royp368/CN/caffe/caffe/examples/imagenet/ilsvrc12_val_lmdb
I0331 13:08:15.219070 260737 data_layer.cpp:80] output data size: 50,3,227,227
I0331 13:08:15.278161 260737 net.cpp:210] Setting up data
I0331 13:08:15.278288 260737 net.cpp:217] Top shape: 50 3 227 227 (7729350)
I0331 13:08:15.278347 260737 net.cpp:217] Top shape: 50 (50)
I0331 13:08:15.278388 260737 net.cpp:225] Memory required for data: 30917600
I0331 13:08:15.278434 260737 layer_factory.hpp:114] Creating layer label_data_1_split
I0331 13:08:15.278497 260737 net.cpp:160] Creating Layer label_data_1_split
I0331 13:08:15.278542 260737 net.cpp:596] label_data_1_split <- label
I0331 13:08:15.278638 260737 net.cpp:570] label_data_1_split -> label_data_1_split_0
I0331 13:08:15.278717 260737 net.cpp:570] label_data_1_split -> label_data_1_split_1
I0331 13:08:15.278831 260737 net.cpp:210] Setting up label_data_1_split
I0331 13:08:15.278895 260737 net.cpp:217] Top shape: 50 (50)
I0331 13:08:15.278937 260737 net.cpp:217] Top shape: 50 (50)
I0331 13:08:15.278970 260737 net.cpp:225] Memory required for data: 30918000
I0331 13:08:15.279007 260737 layer_factory.hpp:114] Creating layer conv1
I0331 13:08:15.279079 260737 net.cpp:160] Creating Layer conv1
I0331 13:08:15.279119 260737 net.cpp:596] conv1 <- data
I0331 13:08:15.279168 260737 net.cpp:570] conv1 -> conv1
I0331 13:08:15.378753 260737 net.cpp:210] Setting up conv1
I0331 13:08:15.391979 260737 net.cpp:217] Top shape: 50 96 55 55 (14520000)
I0331 13:08:15.392047 260737 net.cpp:225] Memory required for data: 88998000
I0331 13:08:15.392149 260737 layer_factory.hpp:114] Creating layer relu1
I0331 13:08:15.392370 260737 net.cpp:160] Creating Layer relu1
I0331 13:08:15.392438 260737 net.cpp:596] relu1 <- conv1
I0331 13:08:15.392495 260737 net.cpp:557] relu1 -> conv1 (in-place)
I0331 13:08:15.392561 260737 net.cpp:210] Setting up relu1
I0331 13:08:15.392616 260737 net.cpp:217] Top shape: 50 96 55 55 (14520000)
I0331 13:08:15.392649 260737 net.cpp:225] Memory required for data: 147078000
I0331 13:08:15.392688 260737 layer_factory.hpp:114] Creating layer norm1
I0331 13:08:15.392743 260737 net.cpp:160] Creating Layer norm1
I0331 13:08:15.392845 260737 net.cpp:596] norm1 <- conv1
I0331 13:08:15.392909 260737 net.cpp:570] norm1 -> norm1
I0331 13:08:15.392988 260737 net.cpp:210] Setting up norm1
I0331 13:08:15.393043 260737 net.cpp:217] Top shape: 50 96 55 55 (14520000)
I0331 13:08:15.393075 260737 net.cpp:225] Memory required for data: 205158000
I0331 13:08:15.393112 260737 layer_factory.hpp:114] Creating layer pool1
I0331 13:08:15.393230 260737 net.cpp:160] Creating Layer pool1
I0331 13:08:15.393283 260737 net.cpp:596] pool1 <- norm1
I0331 13:08:15.393334 260737 net.cpp:570] pool1 -> pool1
I0331 13:08:15.393401 260737 net.cpp:210] Setting up pool1
I0331 13:08:15.393450 260737 net.cpp:217] Top shape: 50 96 27 27 (3499200)
I0331 13:08:15.393482 260737 net.cpp:225] Memory required for data: 219154800
I0331 13:08:15.393517 260737 layer_factory.hpp:114] Creating layer conv2
I0331 13:08:15.393581 260737 net.cpp:160] Creating Layer conv2
I0331 13:08:15.393616 260737 net.cpp:596] conv2 <- pool1
I0331 13:08:15.393663 260737 net.cpp:570] conv2 -> conv2
I0331 13:08:15.520858 260737 net.cpp:210] Setting up conv2
I0331 13:08:15.520990 260737 net.cpp:217] Top shape: 50 256 27 27 (9331200)
I0331 13:08:15.521044 260737 net.cpp:225] Memory required for data: 256479600
I0331 13:08:15.521137 260737 layer_factory.hpp:114] Creating layer relu2
I0331 13:08:15.521211 260737 net.cpp:160] Creating Layer relu2
I0331 13:08:15.521260 260737 net.cpp:596] relu2 <- conv2
I0331 13:08:15.521311 260737 net.cpp:557] relu2 -> conv2 (in-place)
I0331 13:08:15.521374 260737 net.cpp:210] Setting up relu2
I0331 13:08:15.521425 260737 net.cpp:217] Top shape: 50 256 27 27 (9331200)
I0331 13:08:15.521461 260737 net.cpp:225] Memory required for data: 293804400
I0331 13:08:15.521500 260737 layer_factory.hpp:114] Creating layer norm2
I0331 13:08:15.521558 260737 net.cpp:160] Creating Layer norm2
I0331 13:08:15.521596 260737 net.cpp:596] norm2 <- conv2
I0331 13:08:15.521646 260737 net.cpp:570] norm2 -> norm2
I0331 13:08:15.521725 260737 net.cpp:210] Setting up norm2
I0331 13:08:15.521827 260737 net.cpp:217] Top shape: 50 256 27 27 (9331200)
I0331 13:08:15.521868 260737 net.cpp:225] Memory required for data: 331129200
I0331 13:08:15.521908 260737 layer_factory.hpp:114] Creating layer pool2
I0331 13:08:15.522032 260737 net.cpp:160] Creating Layer pool2
I0331 13:08:15.522081 260737 net.cpp:596] pool2 <- norm2
I0331 13:08:15.522133 260737 net.cpp:570] pool2 -> pool2
I0331 13:08:15.522205 260737 net.cpp:210] Setting up pool2
I0331 13:08:15.522256 260737 net.cpp:217] Top shape: 50 256 13 13 (2163200)
I0331 13:08:15.522316 260737 net.cpp:225] Memory required for data: 339782000
I0331 13:08:15.522356 260737 layer_factory.hpp:114] Creating layer conv3
I0331 13:08:15.522419 260737 net.cpp:160] Creating Layer conv3
I0331 13:08:15.522456 260737 net.cpp:596] conv3 <- pool2
I0331 13:08:15.522506 260737 net.cpp:570] conv3 -> conv3
I0331 13:08:15.635948 260737 net.cpp:210] Setting up conv3
I0331 13:08:15.636075 260737 net.cpp:217] Top shape: 50 384 13 13 (3244800)
I0331 13:08:15.636121 260737 net.cpp:225] Memory required for data: 352761200
I0331 13:08:15.636209 260737 layer_factory.hpp:114] Creating layer relu3
I0331 13:08:15.636278 260737 net.cpp:160] Creating Layer relu3
I0331 13:08:15.636325 260737 net.cpp:596] relu3 <- conv3
I0331 13:08:15.636379 260737 net.cpp:557] relu3 -> conv3 (in-place)
I0331 13:08:15.636442 260737 net.cpp:210] Setting up relu3
I0331 13:08:15.636492 260737 net.cpp:217] Top shape: 50 384 13 13 (3244800)
I0331 13:08:15.636525 260737 net.cpp:225] Memory required for data: 365740400
I0331 13:08:15.636698 260737 layer_factory.hpp:114] Creating layer conv4
I0331 13:08:15.636831 260737 net.cpp:160] Creating Layer conv4
I0331 13:08:15.636884 260737 net.cpp:596] conv4 <- conv3
I0331 13:08:15.636945 260737 net.cpp:570] conv4 -> conv4
I0331 13:08:15.736158 260737 net.cpp:210] Setting up conv4
I0331 13:08:15.736286 260737 net.cpp:217] Top shape: 50 384 13 13 (3244800)
I0331 13:08:15.736335 260737 net.cpp:225] Memory required for data: 378719600
I0331 13:08:15.736407 260737 layer_factory.hpp:114] Creating layer relu4
I0331 13:08:15.736474 260737 net.cpp:160] Creating Layer relu4
I0331 13:08:15.736515 260737 net.cpp:596] relu4 <- conv4
I0331 13:08:15.736564 260737 net.cpp:557] relu4 -> conv4 (in-place)
I0331 13:08:15.736624 260737 net.cpp:210] Setting up relu4
I0331 13:08:15.736673 260737 net.cpp:217] Top shape: 50 384 13 13 (3244800)
I0331 13:08:15.736706 260737 net.cpp:225] Memory required for data: 391698800
I0331 13:08:15.736742 260737 layer_factory.hpp:114] Creating layer conv5
I0331 13:08:15.736857 260737 net.cpp:160] Creating Layer conv5
I0331 13:08:15.736903 260737 net.cpp:596] conv5 <- conv4
I0331 13:08:15.736958 260737 net.cpp:570] conv5 -> conv5
I0331 13:08:15.812106 260737 net.cpp:210] Setting up conv5
I0331 13:08:15.812242 260737 net.cpp:217] Top shape: 50 256 13 13 (2163200)
I0331 13:08:15.812295 260737 net.cpp:225] Memory required for data: 400351600
I0331 13:08:15.812388 260737 layer_factory.hpp:114] Creating layer relu5
I0331 13:08:15.812471 260737 net.cpp:160] Creating Layer relu5
I0331 13:08:15.812520 260737 net.cpp:596] relu5 <- conv5
I0331 13:08:15.812573 260737 net.cpp:557] relu5 -> conv5 (in-place)
I0331 13:08:15.812636 260737 net.cpp:210] Setting up relu5
I0331 13:08:15.812686 260737 net.cpp:217] Top shape: 50 256 13 13 (2163200)
I0331 13:08:15.812719 260737 net.cpp:225] Memory required for data: 409004400
I0331 13:08:15.812803 260737 layer_factory.hpp:114] Creating layer pool5
I0331 13:08:15.812958 260737 net.cpp:160] Creating Layer pool5
I0331 13:08:15.813020 260737 net.cpp:596] pool5 <- conv5
I0331 13:08:15.813076 260737 net.cpp:570] pool5 -> pool5
I0331 13:08:15.813155 260737 net.cpp:210] Setting up pool5
I0331 13:08:15.813211 260737 net.cpp:217] Top shape: 50 256 6 6 (460800)
I0331 13:08:15.813246 260737 net.cpp:225] Memory required for data: 410847600
I0331 13:08:15.813284 260737 layer_factory.hpp:114] Creating layer fc6
I0331 13:08:15.813345 260737 net.cpp:160] Creating Layer fc6
I0331 13:08:15.813383 260737 net.cpp:596] fc6 <- pool5
I0331 13:08:15.813431 260737 net.cpp:570] fc6 -> fc6
I0331 13:08:18.129863 260737 net.cpp:210] Setting up fc6
I0331 13:08:18.129989 260737 net.cpp:217] Top shape: 50 4096 (204800)
I0331 13:08:18.130025 260737 net.cpp:225] Memory required for data: 411666800
I0331 13:08:18.130087 260737 layer_factory.hpp:114] Creating layer relu6
I0331 13:08:18.130144 260737 net.cpp:160] Creating Layer relu6
I0331 13:08:18.130182 260737 net.cpp:596] relu6 <- fc6
I0331 13:08:18.130228 260737 net.cpp:557] relu6 -> fc6 (in-place)
I0331 13:08:18.130280 260737 net.cpp:210] Setting up relu6
I0331 13:08:18.130350 260737 net.cpp:217] Top shape: 50 4096 (204800)
I0331 13:08:18.130384 260737 net.cpp:225] Memory required for data: 412486000
I0331 13:08:18.130419 260737 layer_factory.hpp:114] Creating layer drop6
I0331 13:08:18.130465 260737 net.cpp:160] Creating Layer drop6
I0331 13:08:18.130501 260737 net.cpp:596] drop6 <- fc6
I0331 13:08:18.130545 260737 net.cpp:557] drop6 -> fc6 (in-place)
I0331 13:08:18.130596 260737 net.cpp:210] Setting up drop6
I0331 13:08:18.130636 260737 net.cpp:217] Top shape: 50 4096 (204800)
I0331 13:08:18.130667 260737 net.cpp:225] Memory required for data: 413305200
I0331 13:08:18.130699 260737 layer_factory.hpp:114] Creating layer fc7
I0331 13:08:18.130789 260737 net.cpp:160] Creating Layer fc7
I0331 13:08:18.130831 260737 net.cpp:596] fc7 <- fc6
I0331 13:08:18.130880 260737 net.cpp:570] fc7 -> fc7
I0331 13:08:19.161541 260737 net.cpp:210] Setting up fc7
I0331 13:08:19.161661 260737 net.cpp:217] Top shape: 50 4096 (204800)
I0331 13:08:19.161866 260737 net.cpp:225] Memory required for data: 414124400
I0331 13:08:19.161944 260737 layer_factory.hpp:114] Creating layer relu7
I0331 13:08:19.162004 260737 net.cpp:160] Creating Layer relu7
I0331 13:08:19.162044 260737 net.cpp:596] relu7 <- fc7
I0331 13:08:19.162091 260737 net.cpp:557] relu7 -> fc7 (in-place)
I0331 13:08:19.162144 260737 net.cpp:210] Setting up relu7
I0331 13:08:19.162185 260737 net.cpp:217] Top shape: 50 4096 (204800)
I0331 13:08:19.162215 260737 net.cpp:225] Memory required for data: 414943600
I0331 13:08:19.162248 260737 layer_factory.hpp:114] Creating layer drop7
I0331 13:08:19.162291 260737 net.cpp:160] Creating Layer drop7
I0331 13:08:19.162323 260737 net.cpp:596] drop7 <- fc7
I0331 13:08:19.162364 260737 net.cpp:557] drop7 -> fc7 (in-place)
I0331 13:08:19.162416 260737 net.cpp:210] Setting up drop7
I0331 13:08:19.162456 260737 net.cpp:217] Top shape: 50 4096 (204800)
I0331 13:08:19.162487 260737 net.cpp:225] Memory required for data: 415762800
I0331 13:08:19.162519 260737 layer_factory.hpp:114] Creating layer fc8
I0331 13:08:19.162572 260737 net.cpp:160] Creating Layer fc8
I0331 13:08:19.162606 260737 net.cpp:596] fc8 <- fc7
I0331 13:08:19.162650 260737 net.cpp:570] fc8 -> fc8
I0331 13:08:19.414340 260737 net.cpp:210] Setting up fc8
I0331 13:08:19.414463 260737 net.cpp:217] Top shape: 50 1000 (50000)
I0331 13:08:19.414499 260737 net.cpp:225] Memory required for data: 415962800
I0331 13:08:19.414559 260737 layer_factory.hpp:114] Creating layer fc8_fc8_0_split
I0331 13:08:19.414613 260737 net.cpp:160] Creating Layer fc8_fc8_0_split
I0331 13:08:19.414651 260737 net.cpp:596] fc8_fc8_0_split <- fc8
I0331 13:08:19.414700 260737 net.cpp:570] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0331 13:08:19.414799 260737 net.cpp:570] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0331 13:08:19.414870 260737 net.cpp:210] Setting up fc8_fc8_0_split
I0331 13:08:19.414914 260737 net.cpp:217] Top shape: 50 1000 (50000)
I0331 13:08:19.414952 260737 net.cpp:217] Top shape: 50 1000 (50000)
I0331 13:08:19.414983 260737 net.cpp:225] Memory required for data: 416362800
I0331 13:08:19.415015 260737 layer_factory.hpp:114] Creating layer accuracy
I0331 13:08:19.415082 260737 net.cpp:160] Creating Layer accuracy
I0331 13:08:19.415117 260737 net.cpp:596] accuracy <- fc8_fc8_0_split_0
I0331 13:08:19.415156 260737 net.cpp:596] accuracy <- label_data_1_split_0
I0331 13:08:19.415204 260737 net.cpp:570] accuracy -> accuracy
I0331 13:08:19.415267 260737 net.cpp:210] Setting up accuracy
I0331 13:08:19.415310 260737 net.cpp:217] Top shape: (1)
I0331 13:08:19.415341 260737 net.cpp:225] Memory required for data: 416362804
I0331 13:08:19.415375 260737 layer_factory.hpp:114] Creating layer loss
I0331 13:08:19.415417 260737 net.cpp:160] Creating Layer loss
I0331 13:08:19.415452 260737 net.cpp:596] loss <- fc8_fc8_0_split_1
I0331 13:08:19.415488 260737 net.cpp:596] loss <- label_data_1_split_1
I0331 13:08:19.415530 260737 net.cpp:570] loss -> loss
I0331 13:08:19.415585 260737 layer_factory.hpp:114] Creating layer loss
I0331 13:08:19.416146 260737 net.cpp:210] Setting up loss
I0331 13:08:19.416261 260737 net.cpp:217] Top shape: (1)
I0331 13:08:19.416298 260737 net.cpp:220]     with loss weight 1
I0331 13:08:19.416363 260737 net.cpp:225] Memory required for data: 416362808
I0331 13:08:19.416399 260737 net.cpp:287] loss needs backward computation.
I0331 13:08:19.416437 260737 net.cpp:289] accuracy does not need backward computation.
I0331 13:08:19.416473 260737 net.cpp:287] fc8_fc8_0_split needs backward computation.
I0331 13:08:19.416507 260737 net.cpp:287] fc8 needs backward computation.
I0331 13:08:19.416539 260737 net.cpp:287] drop7 needs backward computation.
I0331 13:08:19.416570 260737 net.cpp:287] relu7 needs backward computation.
I0331 13:08:19.416601 260737 net.cpp:287] fc7 needs backward computation.
I0331 13:08:19.416633 260737 net.cpp:287] drop6 needs backward computation.
I0331 13:08:19.416664 260737 net.cpp:287] relu6 needs backward computation.
I0331 13:08:19.416695 260737 net.cpp:287] fc6 needs backward computation.
I0331 13:08:19.416893 260737 net.cpp:287] pool5 needs backward computation.
I0331 13:08:19.416939 260737 net.cpp:287] relu5 needs backward computation.
I0331 13:08:19.416973 260737 net.cpp:287] conv5 needs backward computation.
I0331 13:08:19.417007 260737 net.cpp:287] relu4 needs backward computation.
I0331 13:08:19.417038 260737 net.cpp:287] conv4 needs backward computation.
I0331 13:08:19.417070 260737 net.cpp:287] relu3 needs backward computation.
I0331 13:08:19.417102 260737 net.cpp:287] conv3 needs backward computation.
I0331 13:08:19.417135 260737 net.cpp:287] pool2 needs backward computation.
I0331 13:08:19.417167 260737 net.cpp:287] norm2 needs backward computation.
I0331 13:08:19.417201 260737 net.cpp:287] relu2 needs backward computation.
I0331 13:08:19.417230 260737 net.cpp:287] conv2 needs backward computation.
I0331 13:08:19.417263 260737 net.cpp:287] pool1 needs backward computation.
I0331 13:08:19.417295 260737 net.cpp:287] norm1 needs backward computation.
I0331 13:08:19.417327 260737 net.cpp:287] relu1 needs backward computation.
I0331 13:08:19.417358 260737 net.cpp:287] conv1 needs backward computation.
I0331 13:08:19.417392 260737 net.cpp:289] label_data_1_split does not need backward computation.
I0331 13:08:19.417428 260737 net.cpp:289] data does not need backward computation.
I0331 13:08:19.417457 260737 net.cpp:331] This network produces output accuracy
I0331 13:08:19.417493 260737 net.cpp:331] This network produces output loss
I0331 13:08:19.417568 260737 net.cpp:345] Network initialization done.
I0331 13:08:19.418032 260737 solver.cpp:104] Solver scaffolding done.
I0331 13:08:19.418236 260737 caffe.cpp:310] Starting Optimization
I0331 13:08:19.418290 260737 solver.cpp:340] Solving AlexNet
I0331 13:08:19.418321 260737 solver.cpp:341] Learning Rate Policy: step
I0331 13:08:19.418354 260737 solver.cpp:406] Iteration 0, Testing net (#0)
I0331 13:08:24.035503 260737 solver.cpp:286] Iteration 0, loss = 6.92635
I0331 13:08:24.035661 260737 solver.cpp:303]     Train net output #0: loss = 6.92635 (* 1 = 6.92635 loss)
I0331 13:08:24.035735 260737 sgd_solver.cpp:143] Iteration 0, lr = 0.01
I0331 13:09:25.127256 260737 solver.cpp:382] Iteration 20, loss = 6.90718
I0331 13:09:25.127605 260737 solver.cpp:391] Optimization Done.
I0331 13:09:25.127660 260737 caffe.cpp:313] Optimization Done.

real	1m15.617s
user	35m5.640s
sys	0m17.395s
